{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74cedad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.8.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: idna in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: outcome in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "40b910cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff25ea02",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84af66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Dell\\Desktop\\fliprobonotes\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f5323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c98cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list for scraping the data\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "Date = []\n",
    "Views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c289987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(\"xpath\",'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]'):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"-\")\n",
    "        \n",
    "# Scraping Name of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(\"xpath\",'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]'):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"-\")\n",
    "        \n",
    "# Scraping Artist of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(\"xpath\",'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]'):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"-\")\n",
    "        \n",
    "# Scraping Upload_Date of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(\"xpath\",'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[4]'):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append(\"-\")\n",
    "        \n",
    "# Scraping Views of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(\"xpath\",'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]'):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1aa3249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views (in Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>12.27</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.08</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.61</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>6.01</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.91</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.78</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>5.15</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.92</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.83</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.81</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.69</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.53</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.23</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.82</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.75</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.73</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.72</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.63</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.55</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.49</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.47</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.45</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.40</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.38</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.37</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.37</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.33</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.33</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.30</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.30</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                                  Bath Song   \n",
       "4    5.                               Shape of You   \n",
       "5    6.                              See You Again   \n",
       "6    7.                Phonics Song with Two Words   \n",
       "7    8.                          Wheels on the Bus   \n",
       "8    9.                                Uptown Funk   \n",
       "9   10.  Learning Colors – Colorful Eggs on a Farm   \n",
       "10  11.                              Gangnam Style   \n",
       "11  12.   Masha and the Bear – Recipe for Disaster   \n",
       "12  13.                             Dame Tu Cosita   \n",
       "13  14.                                      Sugar   \n",
       "14  15.                                     Axel F   \n",
       "15  16.                                       Roar   \n",
       "16  17.                             Counting Stars   \n",
       "17  18.                                      Sorry   \n",
       "18  19.                          Thinking Out Loud   \n",
       "19  20.                        Baa Baa Black Sheep   \n",
       "20  21.           Waka Waka (This Time for Africa)   \n",
       "21  22.                                 Dark Horse   \n",
       "22  23.                                      Faded   \n",
       "23  24.                                 Let Her Go   \n",
       "24  25.                             Girls Like You   \n",
       "25  26.                                    Perfect   \n",
       "26  27.                                   Bailando   \n",
       "27  28.                                    Lean On   \n",
       "28  29.          Humpty the train on a fruits ride   \n",
       "29  30.                             Lakdi Ki Kathi   \n",
       "\n",
       "                                           Artist Upload Date  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories       12.27   \n",
       "1                                      Luis Fonsi        8.08   \n",
       "2                                     LooLoo Kids        6.61   \n",
       "3                      Cocomelon – Nursery Rhymes        6.01   \n",
       "4                                      Ed Sheeran        5.91   \n",
       "5                                     Wiz Khalifa        5.78   \n",
       "6                                       ChuChu TV        5.15   \n",
       "7                      Cocomelon – Nursery Rhymes        4.92   \n",
       "8                                     Mark Ronson        4.83   \n",
       "9                                     Miroshka TV        4.81   \n",
       "10                                            Psy        4.69   \n",
       "11                                     Get Movies        4.53   \n",
       "12                                      El Chombo        4.23   \n",
       "13                                       Maroon 5        3.82   \n",
       "14                                     Crazy Frog        3.75   \n",
       "15                                     Katy Perry        3.73   \n",
       "16                                    OneRepublic        3.72   \n",
       "17                                  Justin Bieber        3.63   \n",
       "18                                     Ed Sheeran        3.55   \n",
       "19                     Cocomelon – Nursery Rhymes        3.49   \n",
       "20                                        Shakira        3.47   \n",
       "21                                     Katy Perry        3.45   \n",
       "22                                    Alan Walker        3.40   \n",
       "23                                      Passenger        3.38   \n",
       "24                                       Maroon 5        3.37   \n",
       "25                                     Ed Sheeran        3.37   \n",
       "26                               Enrique Iglesias        3.33   \n",
       "27                                    Major Lazer        3.33   \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs        3.30   \n",
       "29                                   Jingle Toons        3.30   \n",
       "\n",
       "   Views (in Billions)  \n",
       "0        June 17, 2016  \n",
       "1     January 12, 2017  \n",
       "2      October 8, 2016  \n",
       "3          May 2, 2018  \n",
       "4     January 30, 2017  \n",
       "5        April 6, 2015  \n",
       "6        March 6, 2014  \n",
       "7         May 24, 2018  \n",
       "8    November 19, 2014  \n",
       "9    February 27, 2018  \n",
       "10       July 15, 2012  \n",
       "11    January 31, 2012  \n",
       "12       April 5, 2018  \n",
       "13    January 14, 2015  \n",
       "14       June 16, 2009  \n",
       "15   September 5, 2013  \n",
       "16        May 31, 2013  \n",
       "17    October 22, 2015  \n",
       "18     October 7, 2014  \n",
       "19       June 25, 2018  \n",
       "20        June 4, 2010  \n",
       "21   February 20, 2014  \n",
       "22    December 3, 2015  \n",
       "23       July 25, 2012  \n",
       "24        May 31, 2018  \n",
       "25    November 9, 2017  \n",
       "26      April 11, 2014  \n",
       "27      March 22, 2015  \n",
       "28    January 26, 2018  \n",
       "29       June 14, 2018  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating DataFrame for scraped data\n",
    "Wiki = pd.DataFrame({})\n",
    "Wiki['Rank'] = Rank\n",
    "Wiki['Name'] = Name\n",
    "Wiki['Artist'] = Artist\n",
    "Wiki['Upload Date'] = Date\n",
    "Wiki['Views (in Billions)'] = Views\n",
    "\n",
    "# removing stray numbers from Name column\n",
    "Wiki.Name = Wiki.Name.apply(lambda x:x[:-4].strip('\"'))\n",
    "Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "751dc705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),\n",
    "len(Name),\n",
    "len(Artist),\n",
    "len(Date),\n",
    "len(Views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ac4eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd576328",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP ofIndia fromstatisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1717c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Dell\\Desktop\\fliprobonotes\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c777c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://statisticstimes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45cf67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "Name = []\n",
    "Description = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3396bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on Economy button\n",
    "driver.find_element(\"xpath\",\"//div[@class='navbar']/div[2]/button\").click()\n",
    "\n",
    "# clicking on India\n",
    "driver.find_element(\"xpath\",\"//div[@class='dropdown-content']/a[3]\").click()\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking on GDP of Indian Economy\n",
    "GDP = driver.find_element(\"xpath\",\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\").click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df6e3a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDP_billion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c2e0f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements(\"xpath\",\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "    \n",
    "# scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(\"xpath\",\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "    \n",
    "# scraping GSDP at current price (19-20)\n",
    "try:\n",
    "    for i in driver.find_elements(\"xpath\",\"//table[@class='display dataTable']/tbody/tr/td[3]\"):\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP1.append(\"_\")\n",
    "    \n",
    "# scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(\"xpath\",\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "    \n",
    "# scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(\"xpath\",\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")\n",
    "    \n",
    "# scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(\"xpath\",\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe7d81d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP at current price (19-20)</th>\n",
       "      <th>GSDP at current price (18-19)</th>\n",
       "      <th>Share (18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,391</td>\n",
       "      <td>25,141</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>24,534</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>22,488</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>24,424</td>\n",
       "      <td>20,947</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                      State GSDP at current price (19-20)  \\\n",
       "0      1                Maharashtra                             -   \n",
       "1      2                 Tamil Nadu                     1,845,853   \n",
       "2      3              Uttar Pradesh                     1,687,818   \n",
       "3      4                    Gujarat                             -   \n",
       "4      5                  Karnataka                     1,631,977   \n",
       "..   ...                        ...                           ...   \n",
       "127   29                     Sikkim                        28,391   \n",
       "128   30                   Nagaland                             -   \n",
       "129   31          Arunachal Pradesh                             -   \n",
       "130   32                    Mizoram                        24,424   \n",
       "131   33  Andaman & Nicobar Islands                             -   \n",
       "\n",
       "    GSDP at current price (18-19) Share (18-19) GDP($ billion)  \n",
       "0                       2,632,792        13.94%        399.921  \n",
       "1                       1,630,208         8.63%        247.629  \n",
       "2                       1,584,764         8.39%        240.726  \n",
       "3                       1,502,899         7.96%        228.290  \n",
       "4                       1,493,127         7.91%        226.806  \n",
       "..                            ...           ...            ...  \n",
       "127                        25,141         0.15%         17,060  \n",
       "128                        24,534         0.15%              -  \n",
       "129                        22,488         0.13%              -  \n",
       "130                        20,947         0.13%         17,797  \n",
       "131                             -             -              -  \n",
       "\n",
       "[132 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating DataFrame from the scraped data\n",
    "GDP = pd.DataFrame({})\n",
    "GDP['Rank'] = Rank\n",
    "GDP['State'] = State\n",
    "GDP['GSDP at current price (19-20)'] = GSDP1\n",
    "GDP['GSDP at current price (18-19)'] = GSDP2\n",
    "GDP['Share (18-19)'] = Share\n",
    "GDP['GDP($ billion)'] = GDP_billion\n",
    "GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3cf617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51879a",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "418bdade",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Dell\\Desktop\\fliprobonotes\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1afa2cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8eb86df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59a8d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Book_name\n",
    "book_name=driver.find_elements('xpath',\"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "for i in book_name:\n",
    "    if i.text is None:\n",
    "        Book_name.append('--')\n",
    "    else:\n",
    "        Book_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8df26d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Author_name\n",
    "author_name=driver.find_elements('xpath',\"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "for i in author_name:\n",
    "    if i.text is None:\n",
    "        Author_name.append('--')\n",
    "    else:\n",
    "        Author_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2df8b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Volumes_sold\n",
    "volumes_sold=driver.find_elements('xpath',\"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "for i in volumes_sold:\n",
    "    if i.text is None:\n",
    "        Volumes_sold.append('--')\n",
    "    else:\n",
    "        Volumes_sold.append(i.text)\n",
    "        \n",
    "# Scraping Author_name\n",
    "publisher=driver.find_elements('xpath',\"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "for i in publisher:\n",
    "    if i.text is None:\n",
    "        Publisher.append('--')\n",
    "    else:\n",
    "        Publisher.append(i.text)\n",
    "        \n",
    "# Scraping Genre\n",
    "genre=driver.find_elements('xpath',\"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "for i in genre:\n",
    "    if i.text is None:\n",
    "        Genre.append('--')\n",
    "    else:\n",
    "        Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffdaad94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_selling_book=pd.DataFrame({})\n",
    "Top_selling_book['Book_name']=Book_name\n",
    "Top_selling_book['Author_name']=Author_name\n",
    "Top_selling_book['Volumes_sold']=Volumes_sold\n",
    "Top_selling_book['Publisher']=Publisher\n",
    "Top_selling_book['Genre']=Genre\n",
    "Top_selling_book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e824a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91076aa6",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s internationalfixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a7d8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Dell\\Desktop\\fliprobonotes\\chromedriver.exe\")\n",
    "url = 'https://www.bcci.tv/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db1330f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception handeled\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    btn=driver.find_element('xpath',\"//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']/div/ul/li/a\")\n",
    "    driver.get(btn.get_attribute(\"href\"))\n",
    "    time.sleep(3)\n",
    "except NoSuchElementException:\n",
    "    print('exception handeled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a898117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping the data\n",
    "Match_Title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5cc8d8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Match Title, Series, Place, Date, Time]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in driver.find_elements('xpath',\"//div[@class='fixture__format-strip']/span[@class='u-unskewed-text fixture__format']\"):\n",
    "    Match_Title.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements('xpath',\"//div[@class='fixture__format-strip']/span[@class='u-unskewed-text fixture__tournament-label u-truncated']\"):\n",
    "    Series.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements('xpath',\"//div[@class='fixture__description u-unskewed-text']/p/span\"):\n",
    "    Place.append(i.text)\n",
    "        \n",
    "for i in driver.find_elements('xpath',\"//span[@class='fixture__datetime tablet-only']/strong[1]\"):\n",
    "    Date.append(i.text.replace('\\n',' '))\n",
    "\n",
    "date=[i.split(' ',3)[:3] for i in Date]\n",
    "date=[' '.join(i) for i in date]\n",
    "Time=[i.split(' ',3)[-1] for i in Date]\n",
    "fixture=pd.DataFrame({'Match Title': Match_Title,\n",
    "                          \"Series\": Series,\n",
    "                          \"Place\": Place,\n",
    "                          \"Date\": date,\n",
    "                          \"Time\": Time})\n",
    "fixture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a825d",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a63a36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Dell\\Desktop\\fliprobonotes\\chromedriver.exe\")\n",
    "url = (\"https://github.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ae4568e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "handeld\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    Explore=driver.find_element('xpath',\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\").click()\n",
    "    Treading=driver.find_element('xpath',\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\").click()\n",
    "except NoSuchElementException:\n",
    "    print('handeld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d07861f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating emplty list \n",
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0266418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Repository_title\n",
    "repository_title=driver.find_elements(\"xpath\",\"//h1[@class='h3 lh-condensed']\")\n",
    "for i in repository_title:\n",
    "    if i.text is None:\n",
    "        Repository_title.append('--')\n",
    "    else:\n",
    "        Repository_title.append(i.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "844d12b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Repository_description\n",
    "repository_description=driver.find_elements(\"xpath\",\"//p[@class='col-9 color-text-secondary my-1 pr-4']\")\n",
    "for i in repository_description:\n",
    "    if i.text is None:\n",
    "        Repository_description.append('--')\n",
    "    else:\n",
    "        Repository_description.append(i.text)\n",
    "        \n",
    "\n",
    "#scraping Contributors_count\n",
    "contributors_count=driver.find_elements(\"xpath\",\"//div[@class='f6 color-text-secondary mt-2']/a[2]\")\n",
    "for i in contributors_count:\n",
    "    if i.text is None:\n",
    "        Contributors_count.append('--')\n",
    "    else:\n",
    "        Contributors_count.append(i.text)\n",
    "        \n",
    "\n",
    "#scraping Language_used\n",
    "language_used=driver.find_elements(\"xpath\",\"//div[@class='f6 color-text-secondary mt-2']/span[1]\")\n",
    "for i in language_used:\n",
    "    if i.text is None:\n",
    "        Language_used.append('--')\n",
    "    else:\n",
    "        Language_used.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38a6e1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Repository_title, Repository_description, Contributors_count, Language_used]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Treding_rep=pd.DataFrame({})\n",
    "Treding_rep['Repository_title']= Repository_title\n",
    "Treding_rep['Repository_description']= Repository_description\n",
    "Treding_rep['Contributors_count']= Contributors_count\n",
    "Treding_rep['Language_used']= Language_used\n",
    "Treding_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e9327",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdceb97",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "00466058",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Dell\\Desktop\\fliprobonotes\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "79ddc6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.billboard.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "87ac3876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on option button\n",
    "elem=driver.find_elements('xpath',\"//a[@class='header__main-link header__main-link--charts']\")\n",
    "if len(elem) > 0:\n",
    "    elem[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "770e6fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Song_Name = []\n",
    "Artist_Name =[]\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d473603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting urls for top 100 songs\n",
    "urls = driver.find_elements('xpath',\"//li[@class='header__submenu__list__element']//a\")\n",
    "#page_url = urls.get_attribute(\"href\")\n",
    "#driver.get(page_url)\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ce63f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data of song names\n",
    "for i in driver.find_elements('xpath',\"//span[@class='chart-element__information__song text--truncate color--primary']\"):\n",
    "    Song_Name.append(i.text)\n",
    "    \n",
    "# scraping data of artist names\n",
    "for i in driver.find_elements('xpath',\"//span[@class='chart-element__information__artist text--truncate color--secondary']\"):\n",
    "    Artist_Name.append(i.text)\n",
    "    \n",
    "# scraping data of last week ranks\n",
    "for i in driver.find_elements('xpath',\"//div[@class='chart-element__meta text--center color--secondary text--last']\"):\n",
    "    Last_week_rank.append(i.text)\n",
    "    \n",
    "\n",
    "# scraping data of peak ranks\n",
    "for i in driver.find_elements('xpath',\"//div[@class='chart-element__meta text--center color--secondary text--peak']\"):\n",
    "    Peak_rank.append(i.text)       \n",
    "    \n",
    "    \n",
    "# scraping data of weeks on board\n",
    "for i in driver.find_elements('xpath',\"//div[@class='chart-element__meta text--center color--secondary text--week']\"):\n",
    "    Weeks_on_board.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59d32cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Artist, Last Week Rank, Peak Rank, Weeks on board]\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "billiboard = pd.DataFrame({})\n",
    "billiboard['Name'] = Song_Name\n",
    "billiboard['Artist'] = Artist_Name\n",
    "billiboard['Last Week Rank'] = Last_week_rank\n",
    "billiboard['Peak Rank'] = Peak_rank\n",
    "billiboard['Weeks on board'] = Weeks_on_board\n",
    "billiboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e84543",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0a04fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Dell\\Desktop\\fliprobonotes\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "89fb5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://www.imdb.com/list/ls095964455/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a5946672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "38996936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraped data of Names\n",
    "for i in driver.find_elements('xpath',\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Year span\n",
    "for i in driver.find_elements('xpath',\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Genre\n",
    "for i in driver.find_elements('xpath',\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Run time\n",
    "for i in driver.find_elements('xpath',\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Ratings\n",
    "for i in driver.find_elements('xpath',\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Votes\n",
    "for i in driver.find_elements('xpath',\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "110f6b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,123,475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,211,345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,007,174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>297,159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>256,098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>62,627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>202,993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>42,051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>250,826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,123,475  \n",
       "1    51 min     8.7  1,211,345  \n",
       "2    44 min     8.1  1,007,174  \n",
       "3    60 min     7.5    297,159  \n",
       "4    43 min     7.6    256,098  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,741  \n",
       "96   50 min     7.8     62,627  \n",
       "97   42 min     8.1    202,993  \n",
       "98   45 min     7.1     42,051  \n",
       "99  572 min     8.6    250,826  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "TV_Series = pd.DataFrame({})\n",
    "TV_Series['Name'] = Name\n",
    "TV_Series['Year Span'] = Year_span\n",
    "TV_Series['Genre'] = Genre\n",
    "TV_Series['Run Time'] = Run_time\n",
    "TV_Series['Ratings'] = Ratings\n",
    "TV_Series['Votes'] = Votes\n",
    "TV_Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "52167e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b0c4f",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "255b8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\Dell\\Desktop\\fliprobonotes\\chromedriver.exe\")\n",
    "url = (\" https://archive.ics.uci.edu/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4d3244a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_dataste= driver.find_element('xpath',\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\")\n",
    "view_dataste.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "32f847a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping data\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "94203964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Dataset name\n",
    "data_name= driver.find_elements('xpath',\"//p[@class='normal']/b/a[1]\")\n",
    "for i in data_name:\n",
    "    if i.text is None :\n",
    "        Dataset_name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_name.append(i.text)\n",
    "\n",
    "time.sleep(4)        \n",
    "#Scraping data Type\n",
    "data_type=driver.find_elements('xpath',\"//table[@border='1']/tbody/tr/td[2]/p\")\n",
    "for i in data_type[1:]:\n",
    "    if i.text is None :\n",
    "        Data_type.append(\"--\") \n",
    "    else:\n",
    "        Data_type.append(i.text)\n",
    "\n",
    "time.sleep(4) \n",
    "#Scraping Task\n",
    "task=driver.find_elements('xpath',\"//table[@border='1']/tbody/tr/td[3]/p\")\n",
    "for i in task[1:]:\n",
    "    if i.text is None :\n",
    "        Task.append(\"--\") \n",
    "    else:\n",
    "        Task.append(i.text)\n",
    "        \n",
    "time.sleep(4) \n",
    "#Scraping Attribute_type\n",
    "attribute_type=driver.find_elements('xpath',\"//table[@border='1']/tbody/tr/td[4]/p\")\n",
    "for i in attribute_type[1:]:\n",
    "    if i.text is None :\n",
    "        Attribute_type.append(\"--\") \n",
    "    else:\n",
    "        Attribute_type.append(i.text)\n",
    "\n",
    "time.sleep(4)         \n",
    "#Scraping No_of_instances\n",
    "no_of_instances=driver.find_elements('xpath',\"//table[@border='1']/tbody/tr/td[5]/p\")\n",
    "for i in no_of_instances[1:]:\n",
    "    if i.text is None :\n",
    "        No_of_instances.append(\"--\") \n",
    "    else:\n",
    "        No_of_instances.append(i.text)\n",
    "\n",
    "time.sleep(4)         \n",
    "#Scraping No_of_attribute\n",
    "no_of_attribute=driver.find_elements('xpath',\"//table[@border='1']/tbody/tr/td[6]/p\")\n",
    "for i in no_of_attribute[1:]:\n",
    "    if i.text is None :\n",
    "        No_of_attribute.append(\"--\") \n",
    "    else:\n",
    "        No_of_attribute.append(i.text)\n",
    "\n",
    "time.sleep(4) \n",
    "#Scraping Year\n",
    "year=driver.find_elements('xpath',\"//table[@border='1']/tbody/tr/td[7]/p\")\n",
    "for i in year[1:]:\n",
    "    if i.text is None :\n",
    "        Year.append(\"--\") \n",
    "    else:\n",
    "        Year.append(i.text)\n",
    "        \n",
    "data_dataset=pd.DataFrame({})\n",
    "data_dataset['Dataset_name']= Dataset_name\n",
    "data_dataset['Data_type']= Data_type\n",
    "data_dataset['Task']= Task\n",
    "data_dataset['Attribute_type']= Attribute_type\n",
    "data_dataset['No_of_instances']= No_of_instances\n",
    "data_dataset['No_of_attribute']= No_of_attribute\n",
    "data_dataset['Year']= Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9778705c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset_name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data_type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute_type No_of_instances No_of_attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "617               Integer, Real           75840             525   2020   \n",
       "618               Integer, Real             400              50   2020   \n",
       "619                                        1014               7   2020   \n",
       "620                        Real           10129              16   2021   \n",
       "621                        Real            4000               2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d69255bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0de939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
